---
title: "Machine Learning A2"
author: "Kyle Bartlett"
date: "2025-09-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(class)
library(gmodels)

bank <- read.csv("UniversalBank.csv")
```

```{r}
#View(bank)
```


#Make dummies and remove ID and Zip Code
```{r}
bank <- subset(bank, select = -c(ID, ZIP.Code))

bank$Education <- as.factor(bank$Education)
dummies <- dummyVars(" ~ .", data = bank[ , -which(names(bank) == "Personal.Loan")])

bank_dummy <- data.frame(predict(dummies, newdata = bank))

bank_dummy$Personal.Loan <- bank$Personal.Loan

```

#Split data to train and validation
```{r}
set.seed(123)
Index_Train <- createDataPartition(bank_dummy$Personal.Loan, p = 0.6, list = FALSE)
Train <- bank_dummy[Index_Train, ]
Validation <- bank_dummy[-Index_Train, ]
```

#Normalize data and split predictors and labels
```{r}
norm_model <- preProcess(Train[ , -which(names(Train) == "Personal.Loan")], method = c("range"))
Train_norm <- predict(norm_model, Train[ , -which(names(Train) == "Personal.Loan")])
Validation_norm <- predict(norm_model, Validation[ , -which(names(Validation) == "Personal.Loan")])

Train_norm$Personal.Loan <- Train$Personal.Loan
Validation_norm$Personal.Loan <- Validation$Personal.Loan

Train_Predictors <- subset(Train_norm, select = -Personal.Loan)
Validation_Predictors <- subset(Validation_norm, select = -Personal.Loan)

Train_Labels <- Train_norm$Personal.Loan
Validation_Labels <- Validation_norm$Personal.Loan


```

---

#Part 1:
#Run KNN and confusion matrix
```{r}
set.seed(123)
Predicted_Validation <- knn(train = Train_Predictors,test = Validation_Predictors,cl = Train_Labels,k = 1)

CrossTable(x = Validation_Labels, y = Predicted_Validation, prop.chisq = FALSE)
```

#Predict new customer
```{r}
new_customer <- data.frame(Age = 40,Experience = 10,Income = 84,Family = 2,CCAvg = 2,Education = factor(2, levels = c(1,2,3)),Mortgage = 0,Securities.Account = 0,CD.Account = 0,Online = 1,CreditCard = 1)

new_customer_dummy <- predict(dummies, new_customer)

new_customer_norm <- predict(norm_model, new_customer_dummy)

predicted_class <- knn(train = Train_Predictors,test = new_customer_norm,cl = Train_Labels,k = 1)


predicted_class
print("The customer will not accept the loan.")
```

---

#Part 2:
#Normalize data
```{r}
norm_model_2 <- preProcess(bank_dummy, method = c("range"))
bank_normalized <- predict(norm_model_2, bank_dummy)
summary(bank_normalized)
```

```{r}
set.seed(123)
Search_grid<-expand.grid(k=1:25)
model <- train(Personal.Loan ~ ., data = bank_normalized, method = "knn",tuneGrid=Search_grid,preProcess='range')

model
plot(model)
```

---

#Part 3:
#Confusion matrix for the validation data
```{r}
set.seed(123)
Predicted_Validation <- knn(train = Train_Predictors,test = Validation_Predictors,cl = Train_Labels,k = 4)

CrossTable(x = Validation_Labels, y = Predicted_Validation, prop.chisq = FALSE)
```

---

#Part 4:
#New customer with best k
```{r}
new_customer_2 <- data.frame(Age=40,Experience=10,Income=84,Family=2,CCAvg=2,Education=factor(2,levels=c(1,2,3)),Mortgage=0,Securities.Account=0,CD.Account=0,Online=1,CreditCard=1)

new_customer_2 <- predict(dummies,newdata=new_customer_2)
new_customer_2 <- predict(norm_model,as.data.frame(new_customer_2))

predicted_class <- knn(train=Train_Predictors,test=new_customer_2,cl=Train_Labels,k=4)

predicted_class
print("The customer will not accept the loan.")
```


---

#Part 5:
#Repartition data
```{r}
Index_Train_2 <- createDataPartition(bank_dummy$Personal.Loan, p = 0.5, list = FALSE)
Train_2 <- bank_dummy[Index_Train_2, ]
Temp_2  <- bank_dummy[-Index_Train_2, ]

Index_Valid_2 <- createDataPartition(Temp_2$Personal.Loan, p = 0.6, list = FALSE) 
Validation_2 <- Temp_2[Index_Valid_2, ]
Test_2       <- Temp_2[-Index_Valid_2, ]

nrow(Train_2); nrow(Validation_2); nrow(Test_2)
```
#Normalize data
```{r}
norm_model_2 <- preProcess(Train_2[ , -which(names(Train_2) == "Personal.Loan")], 
                           method = c("range"))

Train_2_norm <- predict(norm_model_2, Train_2[ , -which(names(Train_2) == "Personal.Loan")])
Validation_2_norm <- predict(norm_model_2, Validation_2[ , -which(names(Validation_2) == "Personal.Loan")])
Test_2_norm <- predict(norm_model_2, Test_2[ , -which(names(Test_2) == "Personal.Loan")])


Train_2_norm$Personal.Loan <- Train_2$Personal.Loan
Validation_2_norm$Personal.Loan <- Validation_2$Personal.Loan
Test_2_norm$Personal.Loan <- Test_2$Personal.Loan


Train_Predictors_2 <- subset(Train_2_norm, select = -Personal.Loan)
Validation_Predictors_2 <- subset(Validation_2_norm, select = -Personal.Loan)
Test_Predictors_2 <- subset(Test_2_norm, select = -Personal.Loan)

Train_Labels_2 <- Train_2_norm$Personal.Loan
Validation_Labels_2 <- Validation_2_norm$Personal.Loan
Test_Labels_2 <- Test_2_norm$Personal.Loan

```

#Confusion matrix for all 3 sets
```{r}
set.seed(123)
#Train
Predicted_Train_2 <- knn(train = Train_Predictors_2,test  = Train_Predictors_2,cl    = Train_Labels_2,k     = 4)

CrossTable(x = Train_Labels_2, y = Predicted_Train_2, prop.chisq = FALSE)

# Validation
Predicted_Validation_2 <- knn(train = Train_Predictors_2,test  = Validation_Predictors_2,cl    = Train_Labels_2,k     = 4)

CrossTable(x = Validation_Labels_2, y = Predicted_Validation_2, prop.chisq = FALSE)

# Test
Predicted_Test_2 <- knn(train = Train_Predictors_2,test  = Test_Predictors_2,cl    = Train_Labels_2,k     = 4)

CrossTable(x = Test_Labels_2, y = Predicted_Test_2, prop.chisq = FALSE)
```

#Comments:
#The training confusion matrix has better accuracy than the validation and test sets, which makes sense since the model has already seen the training data. The validation and test accuracy were similar indicating k=4 is a good fit and its not over or under fitting the data. The small differences are because of the sampling variation between the 3 sets and the larger gap is consistent with the model best knowing the training data. To conclude, the model is consistently predicting unseen data well.
