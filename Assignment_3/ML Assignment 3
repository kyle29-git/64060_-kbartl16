---
title: "Assignment 3 Naive Bayes"
author: "Kyle Bartlett"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(e1071)
library(caret)
library(ISLR)
library(dplyr)
library(tidyr)
library(gmodels)
```


```{r}
df <- read.csv("UniversalBank.csv")

head(df)
summary(df)
```


Select variables

```{r}
MyData <- df %>%
  rename(Loan = Personal.Loan, CC = CreditCard) %>%
  select(Online, CC, Loan) %>%
  mutate(across(everything(), as.factor))

str(MyData)
```

Create data Partition 

```{r}
set.seed(123)
Index_Train <- createDataPartition(MyData$Loan, p = 0.8, list = FALSE)
Train <- MyData[Index_Train, ]
Test <- MyData[-Index_Train, ]

```




**A. Pivot table for training data**

```{r}
Pivot_Table <- table(CC = Train$CC, Loan = Train$Loan, Online = Train$Online)
Pivot_Table

```




**B. Probability that a customer with CC=1 and Online=1 will accept the loan**

```{r}
SubCounts <- Pivot_Table["1", , "1"]
CountLoan1 <- SubCounts["1"]
CountTotal <- sum(SubCounts)

ProbPivot <- CountLoan1 / CountTotal
ProbPivot
```




**C. Two pivot tables: Loan vs Online and Loan vs CC**

```{r}
LoanOnline <- table(Train$Loan, Train$Online)
Loancc <- table(Train$Loan, Train$CC)
LoanOnline
Loancc
```




**D. Probabilities**

```{r}
# i. P(CC = 1 | Loan = 1)
P_CC1_Loan1 <- Loancc["1", "1"] / sum(Loancc["1", ])

# ii. P(Online = 1 | Loan = 1)
P_Online1_Loan1 <- LoanOnline["1", "1"] / sum(LoanOnline["1", ])

# iii. P(Loan = 1)
P_Loan1 <- sum(Train$Loan == 1) / nrow(Train)

# iv. P(CC = 1 | Loan = 0)
P_CC1_Loan0 <- Loancc["0", "1"] / sum(Loancc["0", ])

# v. P(Online = 1 | Loan = 0)
P_Online1_Loan0 <- LoanOnline["0", "1"] / sum(LoanOnline["0", ])

# vi. P(Loan = 0)
P_Loan0 <- sum(Train$Loan == 0) / nrow(Train)

cat("P(CC=1 | Loan=1) =", P_CC1_Loan1, "\n")
cat("P(Online=1 | Loan=1) =", P_Online1_Loan1, "\n")
cat("P(Loan=1) =", P_Loan1, "\n")
cat("P(CC=1 | Loan=0) =", P_CC1_Loan0, "\n")
cat("P(Online=1 | Loan=0) =", P_Online1_Loan0, "\n")
cat("P(Loan=0) =", P_Loan0, "\n")
```




**E. Naive Bayes: P(Loan=1 | CC=1, Online=1)**

Formula:

P(Loan=1 | CC=1, Online=1) = [P(CC=1 | Loan=1) * P(Online=1 | Loan=1) * P(Loan=1)] / Z
where Z = P(CC=1 | Loan=1)P(Online=1 | Loan=1)P(Loan=1) + P(CC=1 | Loan=0)P(Online=1 | Loan=0)P(Loan=0)

```{r}
num <- P_CC1_Loan1 * P_Online1_Loan1 * P_Loan1
den <- num + (P_CC1_Loan0 * P_Online1_Loan0 * P_Loan0)
P_NB <- num / den
P_NB
```




**F. Compare value from (E) with pivot-table from (B)**

```{r}
ProbPivot
P_NB

```

This comparison shows there is good consistency between the raw pivot table and the Naive Bayes formula.the pivot table has Pivot table (9.76%) and the Naive Bayes (10.12%).The lower pivot-table percentage is more accurate because itâ€™s directly calculated from the observed data, not estimated through independence assumptions.




**G. Table entries needed to compute P(Loan=1 | CC=1, Online=1)**

You need the conditional probabilities P(CC=1|Loan=1), P(Online=1|Loan=1), P(Loan=1)
Also the prior probabilities P(Loan = 1) and P(Loan = 0)

Naive Bayes model probability for CC=1 & Online=1

```{r}
nb_model <- naiveBayes(Loan ~ CC + Online, data = Train)

new_obs <- data.frame(CC = factor("1", levels = levels(Train$CC)),
                      Online = factor("1", levels = levels(Train$Online)))

pred_raw <- predict(nb_model, new_obs, type = "raw")
model_prob <- pred_raw[1, "1"]

model_prob 
P_NB
```

The outputs are both the same from this model and the model produced in part E.
